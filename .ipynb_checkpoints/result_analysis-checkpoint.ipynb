{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guo/.local/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mplt \n",
    "from matplotlib import cm \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib \n",
    "from matplotlib.ticker import FuncFormatter \n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "import statsmodels as sm \n",
    "from statsmodels.tsa.stattools import acf\n",
    "from statsmodels.tsa.stattools import pacf \n",
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "from statsmodels.stats import diagnostic\n",
    "\n",
    "from utils_libs import *\n",
    "from utils_data_prep import * \n",
    "from mixture import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- set-up ----\n",
    "\n",
    "# ---- MAPE\n",
    "def eval_mape(df):\n",
    "    \n",
    "    diff = df['truth'] - df['pre']\n",
    "    tmp = (abs(diff)/(df['truth']+1e-10))\n",
    "\n",
    "    tmpsum = []\n",
    "    for i in range(len(tmp)):\n",
    "        if abs(df['truth'].iloc[i])>1e-5:\n",
    "            tmpsum.append( tmp[i] )\n",
    "                    \n",
    "    return mean(tmpsum)\n",
    "\n",
    "# ---- RMSE\n",
    "def eval_rmse(df):\n",
    "    return sqrt(mean((df['truth']-df['pre'])**2))\n",
    "    \n",
    "# ---- ACCURACY\n",
    "col_format_mix = ['truth', 'pre', 'pre_v', 'pre_b']\n",
    "col_format_gate = ['vol', 'ob']\n",
    "col_format = ['truth', 'pre']\n",
    "\n",
    "features_ob = [ 'spread', 'weightd spread', 'ask vol.', 'bid vol.', 'vol. diff.', 'ask depth', 'bid depth', \\\n",
    "               'depth diff.', 'bid slope', 'ask slope']\n",
    "\n",
    "models = ['gbt', 'rf', 'xgt', 'bayes', 'gp', 'enet', 'ridge']\n",
    "# 'arima', arimax', 'lasso', 'str', 'strx', 'garch', 'egarch'\n",
    "\n",
    "file_path = \"../bt_results/res/rolling/\"\n",
    "\n",
    "pre_ts = 'pytest_'\n",
    "pre_tr = 'pytrain_'\n",
    "\n",
    "gate_ts = 'gate_test'\n",
    "gate_tr = 'gate_train'\n",
    "\n",
    "post_txt = '.txt'\n",
    "post_dat = '.dat'\n",
    "\n",
    "weight_pre = '_weight_pre'\n",
    "weight_gate = '_weight_gate'\n",
    "\n",
    "bin_bound = []\n",
    "for i in range(50):\n",
    "    bin_bound.append(i*0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PLOT prediction and truth \n",
    "for i in range(2,14):\n",
    "    \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(19,8))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    ax[0][0].plot(df['truth'], label = 'truth')\n",
    "    ax[0][0].plot(df['pre'], label = 'mixture pre')\n",
    "    ax[0][0].legend()\n",
    "    ax[0][0].set_ylim([0,1])\n",
    "    \n",
    "    k = 0\n",
    "    for k in range(1, 4):\n",
    "        tmp_mdl = models[k-1]\n",
    "        \n",
    "        file_name = str(i) + '_' + pre_ts + tmp_mdl + post_txt\n",
    "        df = pd.read_csv( file_path + file_name, sep=',', names = col_format)\n",
    "        \n",
    "        ax[0][k].plot(df['truth'], label = 'truth')\n",
    "        ax[0][k].plot(df['pre'], label = tmp_mdl + ' pre')\n",
    "        ax[0][k].legend()\n",
    "        ax[0][k].set_ylim([0,1])\n",
    "        \n",
    "        \n",
    "    for k in range( 4):\n",
    "        tmp_mdl = models[k+3]\n",
    "        \n",
    "        file_name = str(i) + '_' + pre_ts + tmp_mdl + post_txt\n",
    "        df = pd.read_csv( file_path + file_name, sep=',', names = col_format)\n",
    "        \n",
    "        ax[1][k].plot(df['truth'], label = 'truth')\n",
    "        ax[1][k].plot(df['pre'], label = tmp_mdl + ' pre')\n",
    "        ax[1][k].legend()\n",
    "        ax[1][k].set_ylim([0,1])\n",
    "        \n",
    "        \n",
    "    fig.savefig('../bt_results/res/pics/pre_test_' + str(i-1) + '.jpeg', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- RMSE\n",
      "interval  1 :  [0.073900023067522497, 0.088393956171109192, 0.078211463087352578, 0.083732267960057422, 0.08783687699442061, 0.087825280244581083, 0.078092453459051733, 0.083009415488212029]\n",
      "interval  2 :  [0.060157979904919494, 0.064614483591748081, 0.060024253643625521, 0.059368972068381091, 0.065811029560769577, 0.063393061303392853, 0.058990643361074555, 0.061007591860943157]\n",
      "interval  3 :  [0.043440453839300161, 0.048029502076402684, 0.045798185050094808, 0.045505068586124638, 0.047460971694223406, 0.047127068068155892, 0.046707556262830713, 0.047147063738557725]\n",
      "interval  4 :  [0.11002093429993223, 0.11547183883520619, 0.12682473354671084, 0.11137653643301758, 0.11366155409123714, 0.11330439195792741, 0.1099800318613271, 0.10998003186132713]\n",
      "interval  5 :  [0.05711755712675376, 0.063356698192017183, 0.061469125277998117, 0.059691761315813566, 0.058496711410308745, 0.083339027941627647, 0.059050614706894454, 0.058528552712739414]\n",
      "interval  6 :  [0.076593455979249755, 0.080569768154840779, 0.080862063078337598, 0.075898541506817602, 0.079645732890391049, 0.079576243136482233, 0.080897606425114482, 0.079509169847969852]\n",
      "interval  7 :  [0.12109136287129499, 0.15297561964801473, 0.15978352181005517, 0.15064896847003564, 0.12809575125279016, 0.18457976010386515, 0.12375535337786554, 0.12375535337786668]\n",
      "interval  8 :  [0.25782077404475451, 0.28391929640722863, 0.28741154919718687, 0.26095012554896441, 0.25566439845369321, 0.27546583118284157, 0.25700320735123006, 0.25541191113001421]\n",
      "interval  9 :  [0.17960877843053311, 0.20147765699223125, 0.21073852613172134, 0.1841036984041064, 0.18548645832317329, 0.18833591673572828, 0.18336886677766184, 0.18455727828826876]\n",
      "interval  10 :  [0.089908911626904231, 0.11277087490325335, 0.10761641452601048, 0.10100818414541751, 0.10903200813973192, 0.1092318732889669, 0.1101883856679241, 0.10666735065710158]\n",
      "interval  11 :  [0.025235532151117707, 0.075507477331909198, 0.077196374693094608, 0.05269703497298369, 0.052837090623649059, 0.056139756024594978, 0.054994414667419673, 0.052794651814372408]\n",
      "interval  12 :  [0.031338650908644759, 0.037359373321158983, 0.033256425252593994, 0.032496988384540251, 0.037894387788474232, 0.036465707479948269, 0.034550597541967688, 0.034829665999401974]\n",
      "\n",
      " --- MAPE\n",
      "interval  1 :  [0.36698615668246992, 0.44727644686069779, 0.38443312388422868, 0.48783732330361118, 0.56138789811239675, 0.50382905066752626, 0.39533425710763287, 0.48694136266278498]\n",
      "interval  2 :  [0.38121285997878168, 0.58356820173046275, 0.53844541315954819, 0.48486792245390897, 0.60038836151875563, 0.62161601316907067, 0.52141660266947754, 0.53217759016191091]\n",
      "interval  3 :  [0.3963535626895654, 0.50362140284637669, 0.56806957314891371, 0.50815037053400358, 0.53570229481116483, 0.5169105054989469, 0.5822061486258332, 0.55573685685048879]\n",
      "interval  4 :  [0.45188673870927121, 0.50872135638965665, 0.49633717403583844, 0.73260779947889687, 0.50362613664791889, 0.52742193198327825, 0.50914151630057514, 0.50914151630057503]\n",
      "interval  5 :  [0.55696314663395352, 0.69934769210664127, 0.71725802935219307, 0.65348449890538474, 0.56474071284874416, 1.0652712461963676, 0.54172029135011834, 0.55711599736856243]\n",
      "interval  6 :  [0.59238620146413079, 0.81316968526762423, 0.80122465226025807, 0.74728312990894352, 0.77802638134975588, 0.74839952266867504, 0.92924660095155376, 0.82311381371300585]\n",
      "interval  7 :  [0.64202831374530811, 0.82199899831565748, 0.84556842795464304, 1.1237291376520253, 0.73239200501141, 1.0239254534552105, 0.72027849586643422, 0.72027849586666504]\n",
      "interval  8 :  [0.54266712405167716, 0.59363409709096571, 0.57489427814069261, 0.6178296516959022, 0.57627596743523413, 0.66100271497002427, 0.58710056294997426, 0.57914168158554724]\n",
      "interval  9 :  [1.1002177581011903, 2.3648336568101089, 2.7564437263060144, 1.7902189034678613, 1.4005229520957594, 1.442052998676733, 2.1834517978465162, 1.2179246686324869]\n",
      "interval  10 :  [0.98622076150352433, 1.6780461232001485, 2.0863954586965026, 1.7612590984948993, 1.728930833319499, 1.6999361172486096, 2.3476490490844624, 1.9512523660067604]\n",
      "interval  11 :  [2.0010151531337579, 9.7041575341113422, 12.149195790103214, 9.4209215344990138, 6.9723897295934885, 8.0296254663125151, 6.6541354019817724, 6.9874233787980469]\n",
      "interval  12 :  [2.5296955062552433, 3.2919340932056116, 3.55642644767343, 3.1524497928765856, 3.3555630117516237, 3.0556760580544795, 4.9442532938026869, 4.0481301561645564]\n"
     ]
    }
   ],
   "source": [
    "print ' --- RMSE'\n",
    "# RMSE\n",
    "for i in range(2,14):\n",
    "    \n",
    "    tmp_rmse = []\n",
    "    \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    tmp_rmse.append( eval_rmse(df) )\n",
    "    \n",
    "    for tmp_mdl in models:\n",
    "        \n",
    "        file_name = str(i) + '_' + pre_ts + tmp_mdl + post_txt\n",
    "        df = pd.read_csv( file_path + file_name, sep=',', names = col_format)\n",
    "        \n",
    "        tmp_rmse.append( eval_rmse(df) )\n",
    "        \n",
    "    print 'interval ', i-1, ': ', tmp_rmse\n",
    "    \n",
    "\n",
    "print '\\n --- MAPE'\n",
    "# MAPE\n",
    "for i in range(2,14):\n",
    "    \n",
    "    tmp_rmse = []\n",
    "    tmp_mape = []\n",
    "    \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    tmp_mape.append( eval_mape(df) )\n",
    "    \n",
    "    for tmp_mdl in models:\n",
    "        \n",
    "        file_name = str(i) + '_' + pre_ts + tmp_mdl + post_txt\n",
    "        df = pd.read_csv( file_path + file_name, sep=',', names = col_format)\n",
    "        \n",
    "        tmp_mape.append( eval_mape(df) )\n",
    "        \n",
    "    print 'interval ', i-1, ': ', tmp_mape\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- interval  1\n",
      "[('ask depth', 0.082464404), ('bid depth', 0.075930536), ('bid vol.', 0.066800289)]\n",
      "[('ask vol.', 0.58093202), ('bid vol.', 0.29896119), ('spread', 0.23393463)]\n",
      "\n",
      "\n",
      "-- interval  2\n",
      "[('bid slope', 0.053121876), ('ask depth', 0.051078983), ('weightd spread', 0.047696579)]\n",
      "[('ask slope', 0.48011419), ('bid vol.', 0.4713223), ('ask vol.', 0.3361586)]\n",
      "\n",
      "\n",
      "-- interval  3\n",
      "[('bid vol.', 0.049646925), ('bid depth', 0.038289756), ('depth diff.', 0.02865411)]\n",
      "[('bid vol.', 0.59218699), ('vol. diff.', 0.53714186), ('bid depth', 0.25163889)]\n",
      "\n",
      "\n",
      "-- interval  4\n",
      "[('depth diff.', 0.046639305), ('bid depth', 0.044823021), ('bid slope', 0.044272128)]\n",
      "[('ask vol.', 0.5269171), ('weightd spread', 0.35547352), ('bid slope', 0.26580918)]\n",
      "\n",
      "\n",
      "-- interval  5\n",
      "[('vol. diff.', 0.090040043), ('spread', 0.067294538), ('depth diff.', 0.06528116)]\n",
      "[('ask vol.', 0.56750149), ('spread', 0.32964006), ('bid vol.', 0.26203287)]\n",
      "\n",
      "\n",
      "-- interval  6\n",
      "[('depth diff.', 0.096762083), ('bid depth', 0.075704776), ('vol. diff.', 0.070493206)]\n",
      "[('bid vol.', 0.50719804), ('weightd spread', 0.24688755), ('spread', 0.24629925)]\n",
      "\n",
      "\n",
      "-- interval  7\n",
      "[('ask vol.', 0.10948418), ('bid depth', 0.084912956), ('ask slope', 0.080298647)]\n",
      "[('ask slope', 0.51711011), ('vol. diff.', 0.32890108), ('bid vol.', 0.21104038)]\n",
      "\n",
      "\n",
      "-- interval  8\n",
      "[('ask depth', 0.11152938), ('vol. diff.', 0.10226588), ('bid slope', 0.066312082)]\n",
      "[('ask vol.', 0.47671756), ('weightd spread', 0.26352531), ('bid vol.', 0.17086604)]\n",
      "\n",
      "\n",
      "-- interval  9\n",
      "[('ask vol.', 0.11755489), ('depth diff.', 0.075728446), ('bid depth', 0.073535942)]\n",
      "[('spread', 0.53861225), ('ask vol.', 0.38248202), ('vol. diff.', 0.34437615)]\n",
      "\n",
      "\n",
      "-- interval  10\n",
      "[('ask vol.', 0.12171782), ('depth diff.', 0.086391643), ('vol. diff.', 0.074841477)]\n",
      "[('bid vol.', 0.35732144), ('ask vol.', 0.32145047), ('spread', 0.27982321)]\n",
      "\n",
      "\n",
      "-- interval  11\n",
      "[('depth diff.', 0.077742472), ('bid vol.', 0.071207561), ('vol. diff.', 0.056683253)]\n",
      "[('vol. diff.', 0.70157838), ('bid depth', 0.34542453), ('depth diff.', 0.34192714)]\n",
      "\n",
      "\n",
      "-- interval  12\n",
      "[('bid depth', 0.11806703), ('depth diff.', 0.11553213), ('bid vol.', 0.067386582)]\n",
      "[('bid vol.', 0.48366779), ('weightd spread', 0.28791317), ('vol. diff.', 0.15774573)]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# top-k features over intervals\n",
    "\n",
    "# weight[0] vol temporal, [1] vol bias, [2] order book temporal, [3] order book feature, [4] bias \n",
    "\n",
    "# features_ob = [ 'spread', 'weightd spread', 'ask vol.', 'bid vol.', 'vol. diff.', 'ask depth', 'bid depth', \\\n",
    "#                'depth diff.', 'bid slope', 'ask slope']\n",
    "\n",
    "for i in range(2,14):\n",
    "    \n",
    "    print '-- interval ', i-1\n",
    "    \n",
    "    # DATA\n",
    "    file_name = str(i) + weight_pre + post_dat\n",
    "    tmp_weight = np.load(file_path + file_name)\n",
    "    \n",
    "    \n",
    "#     np.abs(np.flip(np.squeeze(tmp_weight[0]),0)) )\n",
    "#     np.abs(np.flip(np.squeeze(tmp_weight[2]),0)) )\n",
    "    \n",
    "    ft_weight = list(zip(features_ob, np.abs(np.squeeze(tmp_weight[3]))))\n",
    "    \n",
    "    tmp = sorted(ft_weight, key = lambda x: x[1], reverse = True)\n",
    "    print tmp[:3]\n",
    "    \n",
    "    file_name = str(i) + weight_gate + post_dat\n",
    "    tmp_weight = np.load(file_path + file_name)\n",
    "    \n",
    "#     np.abs(np.flip(np.squeeze(tmp_weight[0]),0)) )\n",
    "#     np.abs(np.flip(np.squeeze(tmp_weight[2]),0)) )\n",
    "    \n",
    "    ft_weight = list(zip(features_ob, np.abs(np.squeeze(tmp_weight[3]))))\n",
    "    \n",
    "    tmp = sorted(ft_weight, key = lambda x: x[1], reverse = True)\n",
    "    print tmp[:3]\n",
    "    \n",
    "    print '\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parameter distribution of mixture expert\n",
    "\n",
    "# weight[0] vol temporal, [1] vol bias, [2] order book temporal, [3] order book feature, [4] bias \n",
    "\n",
    "vol_temp = []\n",
    "ob_temp = []\n",
    "ob_ft = []\n",
    "\n",
    "for i in range(2,14):\n",
    "    # DATA\n",
    "    file_name = str(i) + weight_pre + post_dat\n",
    "    tmp_weight = np.load(file_path + file_name)\n",
    "    \n",
    "    vol_temp.append( np.flip(np.squeeze(tmp_weight[0]),0) )\n",
    "    ob_temp.append( np.flip(np.squeeze(tmp_weight[2]),0) )\n",
    "    ob_ft.append( np.squeeze(tmp_weight[3]) )\n",
    "    \n",
    "     # PLOT \n",
    "    fig, ax_list = plt.subplots(1, 3, figsize=(15,4))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    ax_list[0].bar(range(len(np.squeeze(tmp_weight[0]))), np.abs(np.flip(np.squeeze(tmp_weight[0]),0)) )\n",
    "    ax_list[0].set_title('Auto-regressive volatility')\n",
    "    ax_list[0].set(xlabel='Temporal lags', ylabel='weights')\n",
    "    ax_list[0].set_ylim(0,0.2)\n",
    "    \n",
    "    ax_list[1].bar(range(len(np.squeeze(tmp_weight[2]))), np.abs(np.flip(np.squeeze(tmp_weight[2]),0)) )\n",
    "    ax_list[1].set_title('Temporal dependency on order book')\n",
    "    ax_list[1].set(xlabel='Temporal lags')\n",
    "    ax_list[1].set_ylim(0,0.5)\n",
    "    \n",
    "    ax_list[2].bar( range(len(np.squeeze(tmp_weight[3])) ), np.abs(np.squeeze(tmp_weight[3])) )\n",
    "    ax_list[2].set_title('Feature dependency on order book')\n",
    "    tmp_ind = range(len(np.squeeze(tmp_weight[3])))\n",
    "    plt.xticks( tmp_ind , features_ob, rotation=50 )\n",
    "    ax_list[2].set_ylim(0,0.15)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    \n",
    "print np.shape(vol_temp), np.shape(ob_temp), np.shape(ob_ft)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(vol_temp));\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(ob_temp));\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(ob_ft));\n",
    "\n",
    "#    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# parameter distribution of mixture gate\n",
    "\n",
    "# weight[0] vol temporal, [1] vol bias, [2] order book temporal, [3] order book feature, [4] bias \n",
    "\n",
    "vol_temp = []\n",
    "ob_temp = []\n",
    "ob_ft = []\n",
    "\n",
    "for i in range(2,14):\n",
    "    \n",
    "    # DATA\n",
    "    file_name = str(i) + weight_gate + post_dat\n",
    "    tmp_weight = np.load(file_path + file_name)\n",
    "    \n",
    "    vol_temp.append( np.flip(np.squeeze(tmp_weight[0]),0) )\n",
    "    ob_temp.append( np.flip(np.squeeze(tmp_weight[2]),0) )\n",
    "    ob_ft.append( np.squeeze(tmp_weight[3]) )\n",
    "    \n",
    "    # PLOT \n",
    "    fig, ax_list = plt.subplots(1, 3, figsize=(15,4))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    ax_list[0].bar(range(len(np.squeeze(tmp_weight[0]))), np.abs(np.flip(np.squeeze(tmp_weight[0]),0)) )\n",
    "    ax_list[0].set_title('Auto-regressive volatility')\n",
    "    ax_list[0].set(xlabel='Temporal lags', ylabel='weights')\n",
    "    ax_list[0].set_ylim(0,0.5)\n",
    "    \n",
    "    ax_list[1].bar(range(len(np.squeeze(tmp_weight[2]))), np.abs(np.flip(np.squeeze(tmp_weight[2]),0)) )\n",
    "    ax_list[1].set_title('Temporal dependency on order book')\n",
    "    ax_list[1].set(xlabel='Temporal lags')\n",
    "    ax_list[1].set_ylim(0,0.5)\n",
    "    \n",
    "    ax_list[2].bar( range(len(np.squeeze(tmp_weight[3])) ), np.abs(np.squeeze(tmp_weight[3])) )\n",
    "    ax_list[2].set_title('Feature dependency on order book')\n",
    "    tmp_ind = range(len(np.squeeze(tmp_weight[3])))\n",
    "    plt.xticks( tmp_ind , features_ob, rotation=50 )\n",
    "    ax_list[2].set_ylim(0, 1.0)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    \n",
    "print np.shape(vol_temp), np.shape(ob_temp), np.shape(ob_ft)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(vol_temp));\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(ob_temp));\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,3))\n",
    "ax.plot(np.abs(ob_ft));\n",
    "\n",
    "#    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.434108527132\n",
      "0.511278195489\n",
      "0.408163265306\n",
      "0.465753424658\n",
      "0.448979591837\n",
      "0.5\n",
      "0.46875\n",
      "0.530487804878\n",
      "0.543103448276\n",
      "0.444444444444\n",
      "0.387096774194\n",
      "0.533333333333\n"
     ]
    }
   ],
   "source": [
    "# gate and volatility correlation\n",
    "\n",
    "for i in range(2,14):\n",
    "    \n",
    "    # truth in training \n",
    "    file_name = str(i) + '_' + pre_tr + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    y_tr = list(df['truth'])\n",
    "    \n",
    "    # truth in testing\n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    y_ts = list(df['truth'])\n",
    "    \n",
    "    # gates in training\n",
    "    file_name = str(i) + '_' + gate_tr + post_txt\n",
    "    df_tr = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    \n",
    "    # gates in testing\n",
    "    file_name = str(i) + '_' + gate_ts + post_txt\n",
    "    df_ts = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    \n",
    "    # ?\n",
    "    gate_ob = list(df_ts['ob'])\n",
    "    up_idx = []\n",
    "    for j in range(1, len(gate_ob)):\n",
    "        if 1.0*(gate_ob[j]-gate_ob[j-1])/gate_ob[j-1] > 0.9:\n",
    "            up_idx.append(j)\n",
    "    cnt = 0\n",
    "    for k in up_idx:\n",
    "        # ?\n",
    "        if k-1>=0 and y_ts[k]>y_ts[k-1]:\n",
    "            cnt+=1\n",
    "        \n",
    "    print 1.0*cnt/len(up_idx)    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bin_bound = []\n",
    "for i in range(50):\n",
    "    bin_bound.append(i*0.02)\n",
    "\n",
    "for i in range(2,4):\n",
    "    \n",
    "    # truth in training \n",
    "    file_name = str(i) + '_' + pre_tr + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    y_tr = list(df['truth'])\n",
    "    \n",
    "    # truth in testing\n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    y_ts = list(df['truth'])\n",
    "    \n",
    "    # gates in training\n",
    "    file_name = str(i) + '_' + gate_tr + post_txt\n",
    "    df_tr = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    \n",
    "    # gates in testing\n",
    "    file_name = str(i) + '_' + gate_ts + post_txt\n",
    "    df_ts = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,3))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    ax[0].plot(y_tr + y_ts, label = 'Volatility series in training and testing set')\n",
    "    ax[0].axvline( len(y_tr), color = 'r', linewidth = 2.0, linestyle = '--' )\n",
    "    \n",
    "    ax[1].hist(df_tr['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the training data ')\n",
    "    ax[1].set_ylim(0,800)\n",
    "    ax[1].legend(fontsize=10)\n",
    "    \n",
    "    ax[2].hist(df_ts['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the testing data')\n",
    "    ax[2].set_ylim(0,800)\n",
    "    ax[2].legend(fontsize=10)\n",
    "#     ax.legend()\n",
    "#     ax.set_ylim(0,350)\n",
    "#     ax.set_xlim(0,1.0)\n",
    "#     plt.axvline( len(y_tr), color = 'r', linewidth = 2.0, linestyle = '--' )\n",
    "#     plt.title(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# training data   hist, prediction, gate\n",
    "\n",
    "bin_bound = []\n",
    "for i in range(50):\n",
    "    bin_bound.append(i*0.02)\n",
    "\n",
    "for i in range(2, 14):\n",
    "    \n",
    "    # truth in training \n",
    "    file_name = str(i) + '_' + pre_tr + 'mix' + post_txt\n",
    "    df_pre = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    # gates in training\n",
    "    file_name = str(i) + '_' + gate_tr + post_txt\n",
    "    df_gate = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    tmp_gate = np.asarray(df_gate)\n",
    "    \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,3))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    # hist\n",
    "    ax[0].hist(df_gate['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the training data ')\n",
    "    ax[0].set_ylim(0,800)\n",
    "    ax[0].legend(fontsize=10)\n",
    "    \n",
    "    # truth and prediction\n",
    "    ax[1].plot(df_pre['truth'], label = 'Truth')\n",
    "    ax[1].plot(df_pre['pre'], label = 'Prediction')\n",
    "    ax[1].plot(df_pre['pre_v'], label = 'Pre_v')\n",
    "    ax[1].plot(df_pre['pre_b'], label = 'Pre_b')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_ylim(0,3)\n",
    "    \n",
    "    # gate distribution\n",
    "    X = range(len(tmp_gate))\n",
    "    Y =  [1.0 for k in tmp_gate ]\n",
    "    Y1 = [k[0] for k in tmp_gate]\n",
    "    Y2 = [0.0 for k in tmp_gate]\n",
    "    \n",
    "    ax[2].plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "    ax[2].plot(Y1,label = 'Volatility', color = 'k', alpha=.1)\n",
    "    ax[2].plot(Y2,)\n",
    "    ax[2].fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "    ax[2].fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# testing data   hist, prediction, gate\n",
    "\n",
    "for i in range(2, 14):\n",
    "    \n",
    "    \n",
    "    # -- DATA\n",
    "    \n",
    "    # DATA truth in testing  \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df_pre = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    # DATA gates in testing\n",
    "    file_name = str(i) + '_' + gate_ts + post_txt\n",
    "    df_gate = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    tmp_gate = np.asarray(df_gate)\n",
    "    \n",
    "    # -- PLOT\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15,3))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    # hist\n",
    "    ax[0].hist(df_gate['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the testing data ')\n",
    "    ax[0].set_ylim(0,300)\n",
    "    ax[0].legend(fontsize=10)\n",
    "    \n",
    "    # truth and prediction\n",
    "    ax[1].plot(df_pre['truth'], label = 'Truth')\n",
    "    ax[1].plot(df_pre['pre'], label = 'Prediction')\n",
    "    ax[1].plot(df_pre['pre_v'], label = 'Pre_v')\n",
    "    ax[1].plot(df_pre['pre_b'], label = 'Pre_b')\n",
    "    ax[1].legend()\n",
    "    ax[1].set_ylim(0,3)\n",
    "    \n",
    "    # gate distribution\n",
    "    X = range(len(tmp_gate))\n",
    "    Y =  [1.0 for k in tmp_gate ]\n",
    "    Y1 = [k[0] for k in tmp_gate]\n",
    "    Y2 = [0.0 for k in tmp_gate]\n",
    "    \n",
    "    ax[2].plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "    ax[2].plot(Y1,label = 'Volatility', color = 'k', alpha=.1)\n",
    "    ax[2].plot(Y2,)\n",
    "    ax[2].fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "    ax[2].fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# investigation into a certain interval\n",
    "\n",
    "# plt.ioff()\n",
    "    \n",
    "for i in range(3,4):\n",
    "    \n",
    "    # --- DATA\n",
    "    \n",
    "    # DATA truth target values in testing \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df_pre = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    # DATA gates in testing\n",
    "    file_name = str(i) + '_' + gate_ts + post_txt\n",
    "    df_gate = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    tmp_gate = np.asarray(df_gate)\n",
    "    \n",
    "    # DATA feature data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_xtest_mix\" + post_dat\n",
    "    x = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_ytest_mix\" + post_dat\n",
    "    y = np.load(data_path)\n",
    "    \n",
    "    \n",
    "    # DATA minute data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_test\" + post_dat\n",
    "    price_minu_tr = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_train\" + post_dat\n",
    "    price_minu_ts = np.load(data_path)\n",
    "    \n",
    "    \n",
    "    # DATA gate parameters\n",
    "    file_name = str(i) + weight_gate + post_dat\n",
    "    gate_para = np.load(file_path + file_name)\n",
    "    \n",
    "    abs_gate_para = np.abs(gate_para) \n",
    "    \n",
    "    # DATA expert parameters\n",
    "    file_name = str(i) + weight_pre + post_dat\n",
    "    exp_para = np.load(file_path + file_name)\n",
    "    \n",
    "    # auto-regressive volatility, features \n",
    "    vol = np.asarray( [k[0] for k in x] )\n",
    "    ob  = np.asarray( [k[1] for k in x] )\n",
    "    \n",
    "    ob = np.transpose(ob, [2, 1, 0])\n",
    "#     print np.shape(vol), np.shape(ob)\n",
    "    \n",
    "    \n",
    "    # --- plot\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    # truth and prediction\n",
    "#     df_pre = df_pre.iloc[100:200]\n",
    "    ax[0].plot(df_pre['truth'], label = 'Truth')\n",
    "    ax[0].plot(df_pre['pre'],   color ='c', label = 'Prediction', linewidth = 2)\n",
    "    ax[0].plot(df_pre['pre_v'], label = 'pre_v')\n",
    "    ax[0].plot(df_pre['pre_b'],   label = 'pre_b')\n",
    "#     ax[0].set_ylim([0.0, 1.0])\n",
    "    ax[0].legend()\n",
    "    \n",
    "    # gate distribution\n",
    "#     tmp_gate = tmp_gate[100:200]\n",
    "    X = range(len(tmp_gate))\n",
    "    Y =  [1.0 for k in tmp_gate ]\n",
    "    Y1 = [k[0] for k in tmp_gate]\n",
    "    Y2 = [0.0 for k in tmp_gate]\n",
    "    \n",
    "    ax[1].plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "    ax[1].plot(Y1,label = 'Volatility', color = 'k', alpha=.1)\n",
    "    ax[1].plot(Y2,)\n",
    "    ax[1].fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "    ax[1].fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "    \n",
    "    plt.subplots_adjust(top=0.85)\n",
    "    \n",
    "    \n",
    "    # --- PLOT\n",
    "    \n",
    "    fig, ax1 = plt.subplots(5, 2, figsize=(15,12))\n",
    "#     fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "   \n",
    "    max_ob = np.max(ob[0], 0)\n",
    "    min_ob = np.min(ob[0], 0)\n",
    "    print  np.shape(ob),  np.shape(max_ob)\n",
    "    ax1[0][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[0][0].set_ylim([0,10])\n",
    "    \n",
    "    max_ob = np.max(ob[1], 0)\n",
    "    min_ob = np.min(ob[1], 0)\n",
    "    ax1[0][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[0][1].set_ylim([0,10])\n",
    "    \n",
    "    max_ob = np.max(ob[2], 0)\n",
    "    min_ob = np.min(ob[2], 0)\n",
    "    ax1[1][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[1][0].set_ylim([0,350])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[3], 0)\n",
    "    min_ob = np.min(ob[3], 0)\n",
    "    ax1[1][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[1][1].set_ylim([0,500])\n",
    "    \n",
    "    max_ob = np.max(ob[4], 0)\n",
    "    min_ob = np.min(ob[4], 0)\n",
    "    ax1[2][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[2][0].set_ylim([0,200])\n",
    "    \n",
    "    max_ob = np.max(ob[5], 0)\n",
    "    min_ob = np.min(ob[5], 0)\n",
    "    ax1[2][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[2][1].set_ylim([0,5000])\n",
    "\n",
    "    \n",
    "    max_ob = np.max(ob[6], 0)\n",
    "    min_ob = np.min(ob[6], 0)\n",
    "    ax1[3][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[3][0].set_ylim([0,5000])\n",
    "    \n",
    "    max_ob = np.max(ob[7], 0)\n",
    "    min_ob = np.min(ob[7], 0)\n",
    "    ax1[3][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[3][1].set_ylim([-4000,4000])\n",
    "    \n",
    "    max_ob = np.max(ob[8], 0)\n",
    "    min_ob = np.min(ob[8], 0)\n",
    "    ax1[4][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[4][0].set_ylim([0,2000])\n",
    "    \n",
    "    max_ob = np.max(ob[9], 0)\n",
    "    min_ob = np.min(ob[9], 0)\n",
    "    ax1[4][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax1[4][1].set_ylim([0,4000])\n",
    "    \n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    # --- PLOT\n",
    "    \n",
    "    fig, ax2 = plt.subplots( figsize=(15,4))\n",
    "    ax2.plot(price_minu_ts)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# investigation into each interval\n",
    "\n",
    "# TRAINING\n",
    "\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "\n",
    "plt.ioff()\n",
    "    \n",
    "for i in range(2,14):\n",
    "    \n",
    "    # --- DATA\n",
    "    \n",
    "    # DATA truth target values in testing \n",
    "    file_name = str(i) + '_' + pre_tr + 'mix' + post_txt\n",
    "    df_pre = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    # DATA gates in testing\n",
    "    file_name = str(i) + '_' + gate_tr + post_txt\n",
    "    df_gate = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    tmp_gate = np.asarray(df_gate)\n",
    "    \n",
    "    # DATA feature data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_xtrain_mix\" + post_dat\n",
    "    x = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_ytrain_mix\" + post_dat\n",
    "    y = np.load(data_path)\n",
    "    \n",
    "    # DATA gate parameters\n",
    "    file_name = str(i) + weight_gate + post_dat\n",
    "    gate_para = np.load(file_path + file_name)\n",
    "    \n",
    "    abs_gate_para = np.abs(gate_para) \n",
    "    \n",
    "    # DATA expert parameters\n",
    "    file_name = str(i) + weight_pre + post_dat\n",
    "    exp_para = np.load(file_path + file_name)\n",
    "    \n",
    "    # DATA minute data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_train\" + post_dat\n",
    "    price_minu_tr = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_test\" + post_dat\n",
    "    price_minu_ts = np.load(data_path)\n",
    "    \n",
    "    print np.shape(price_minu_tr), np.shape(price_minu_ts)\n",
    "    \n",
    "    # auto-regressive volatility, features \n",
    "    vol = np.asarray( [k[0] for k in x] )\n",
    "    ob  = np.asarray( [k[1] for k in x] )\n",
    "    print np.shape(vol), np.shape(ob)\n",
    "    \n",
    "    # feature first\n",
    "#     ob = np.transpose(ob, [2, 0, 1])\n",
    "#     print  np.shape(ob)\n",
    "    \n",
    "    # data instances with certain gates \n",
    "    pos = []\n",
    "    for j in range(len(tmp_gate)):\n",
    "        if tmp_gate[j][1] >= 0.0 and tmp_gate[j][1] <= 1.0:\n",
    "            pos.append(j)\n",
    "    num = len(pos)\n",
    "    \n",
    "    # sample\n",
    "    np.random.shuffle(pos)\n",
    "    if num<100:\n",
    "        cnt_sample = num\n",
    "    else:\n",
    "        cnt_sample = 100\n",
    "    \n",
    "    vol_sample = vol[pos[:cnt_sample]]\n",
    "    ob_sample = ob[pos[:cnt_sample]]\n",
    "    \n",
    "    # feature first\n",
    "    ob_sample = np.transpose(ob_sample, [2, 0, 1])\n",
    "    \n",
    "    \n",
    "    # --- PLOT\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(5, 3, figsize=(15,15))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    # hist\n",
    "    ax[0][0].hist(df_gate['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the testing data ')\n",
    "    ax[0][0].set_ylim(0,300)\n",
    "    ax[0][0].legend(fontsize=10)\n",
    "    \n",
    "    # truth and prediction\n",
    "#     ax[0][1].plot(df_pre['truth'], label = 'Truth')\n",
    "    ax[0][1].plot(df_pre['pre'],   label = 'Prediction', linewidth = 4)\n",
    "    ax[0][1].plot(df_pre['pre_v'], label = 'pre_v', linewidth = 1)\n",
    "    ax[0][1].plot(df_pre['pre_b'], label = 'pre_b')\n",
    "    ax[0][1].set_ylim([0.0, 3.0])\n",
    "    ax[0][1].legend()\n",
    "    \n",
    "    \n",
    "    # gate distribution\n",
    "    X = range(len(tmp_gate))\n",
    "    Y =  [1.0 for k in tmp_gate ]\n",
    "    Y1 = [k[0] for k in tmp_gate]\n",
    "    Y2 = [0.0 for k in tmp_gate]\n",
    "    \n",
    "    ax[0][2].plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "    ax[0][2].plot(Y1,label = 'Volatility', color = 'k', alpha=.1)\n",
    "    ax[0][2].plot(Y2,)\n",
    "    ax[0][2].fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "    ax[0][2].fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "    \n",
    "    \n",
    "    # features\n",
    "    ob = np.transpose(ob, [2, 1, 0])\n",
    "    print  np.shape(ob)\n",
    "    \n",
    "    max_ob = np.max(ob[0], 0)\n",
    "    min_ob = np.min(ob[0], 0)\n",
    "    ax[1][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][0].set_ylim([0,10])\n",
    "    ax[1][0].set_title(features_ob[0])\n",
    "    \n",
    "    max_ob = np.max(ob[1], 0)\n",
    "    min_ob = np.min(ob[1], 0)\n",
    "    ax[1][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][1].set_ylim([0,10])\n",
    "    ax[1][1].set_title(features_ob[1])\n",
    "    \n",
    "    max_ob = np.max(ob[2], 0)\n",
    "    min_ob = np.min(ob[2], 0)\n",
    "    ax[1][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][2].set_ylim([0,350])\n",
    "    ax[1][2].set_title(features_ob[2])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[3], 0)\n",
    "    min_ob = np.min(ob[3], 0)\n",
    "    ax[2][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][0].set_ylim([0,500])\n",
    "    ax[2][0].set_title(features_ob[3])\n",
    "    \n",
    "    max_ob = np.max(ob[4], 0)\n",
    "    min_ob = np.min(ob[4], 0)\n",
    "    ax[2][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][1].set_ylim([0,200])\n",
    "    ax[2][1].set_title(features_ob[4])\n",
    "    \n",
    "    max_ob = np.max(ob[5], 0)\n",
    "    min_ob = np.min(ob[5], 0)\n",
    "    ax[2][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][2].set_ylim([0,5000])\n",
    "    ax[2][2].set_title(features_ob[5])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[6], 0)\n",
    "    min_ob = np.min(ob[6], 0)\n",
    "    ax[3][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][0].set_ylim([0,5000])\n",
    "    ax[3][0].set_title(features_ob[6])\n",
    "    \n",
    "    max_ob = np.max(ob[7], 0)\n",
    "    min_ob = np.min(ob[7], 0)\n",
    "    ax[3][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][1].set_ylim([-4000,4000])\n",
    "    ax[3][1].set_title(features_ob[7])\n",
    "    \n",
    "    max_ob = np.max(ob[8], 0)\n",
    "    min_ob = np.min(ob[8], 0)\n",
    "    ax[3][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][2].set_ylim([0,2000])\n",
    "    ax[3][2].set_title(features_ob[8])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[9], 0)\n",
    "    min_ob = np.min(ob[9], 0)\n",
    "    ax[4][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[4][0].set_ylim([0,4000])\n",
    "    ax[4][0].set_title(features_ob[9])\n",
    "    \n",
    "    \n",
    "    # price at minutes\n",
    "    ax[4][1].plot(price_minu_tr)\n",
    "#     ax[4][1].set_title('Temporal dependency on order book')\n",
    "#     ax[4][1].set(xlabel='Temporal lags')\n",
    "    ax[4][1].set_ylim([200, 800])\n",
    "    \n",
    "    # feature weights\n",
    "    handler = ax[4][2].bar( range(len(np.squeeze(abs_gate_para[3])) ), np.squeeze(abs_gate_para[3]))\n",
    "    ax[4][2].set_title('Feature weight of order book')\n",
    "    tmp_ind = range(len(np.squeeze(abs_gate_para[3])))\n",
    "    ax[4][2].set_ylim([0, 1.0])\n",
    "    plt.xticks( tmp_ind , features_ob, rotation=50 )\n",
    "    \n",
    "    \n",
    "    # save figure\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    fig.savefig('../bt_results/res/pics/train_' + str(i-1) + '.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# investigation into each interval\n",
    "\n",
    "# TESTING\n",
    "\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "\n",
    "plt.ioff()\n",
    "    \n",
    "for i in range(2,14):\n",
    "    \n",
    "    # --- DATA\n",
    "    \n",
    "    # DATA truth target values in testing \n",
    "    file_name = str(i) + '_' + pre_ts + 'mix' + post_txt\n",
    "    df_pre = pd.read_csv( file_path + file_name, sep=',', names = col_format_mix)\n",
    "    \n",
    "    # DATA gates in testing\n",
    "    file_name = str(i) + '_' + gate_ts + post_txt\n",
    "    df_gate = pd.read_csv( file_path + file_name, sep=',', names = col_format_gate )\n",
    "    tmp_gate = np.asarray(df_gate)\n",
    "    \n",
    "    # DATA feature data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_xtest_mix\" + post_dat\n",
    "    x = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling/\" + str(i) + \"_ytest_mix\" + post_dat\n",
    "    y = np.load(data_path)\n",
    "    \n",
    "    # DATA gate parameters\n",
    "    file_name = str(i) + weight_gate + post_dat\n",
    "    gate_para = np.load(file_path + file_name)\n",
    "    \n",
    "    abs_gate_para = np.abs(gate_para) \n",
    "    \n",
    "    # DATA expert parameters\n",
    "    file_name = str(i) + weight_pre + post_dat\n",
    "    exp_para = np.load(file_path + file_name)\n",
    "    \n",
    "    # DATA minute data\n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_train\" + post_dat\n",
    "    price_minu_tr = np.load(data_path)\n",
    "    \n",
    "    data_path = \"../dataset/bitcoin/training_data/rolling_minu/\" + str(i) + \"_test\" + post_dat\n",
    "    price_minu_ts = np.load(data_path)\n",
    "    print np.shape(price_minu_tr), np.shape(price_minu_ts)\n",
    "    \n",
    "    # auto-regressive volatility, features \n",
    "    vol = np.asarray( [k[0] for k in x] )\n",
    "    ob  = np.asarray( [k[1] for k in x] )\n",
    "    print np.shape(vol), np.shape(ob)\n",
    "    \n",
    "    # feature first\n",
    "#     ob = np.transpose(ob, [2, 0, 1])\n",
    "#     print  np.shape(ob)\n",
    "    \n",
    "    # data instances with certain gates \n",
    "    pos = []\n",
    "    for j in range(len(tmp_gate)):\n",
    "        if tmp_gate[j][1] >= 0.0 and tmp_gate[j][1] <= 1.0:\n",
    "            pos.append(j)\n",
    "    num = len(pos)\n",
    "    \n",
    "    # sample\n",
    "    np.random.shuffle(pos)\n",
    "    if num<100:\n",
    "        cnt_sample = num\n",
    "    else:\n",
    "        cnt_sample = 100\n",
    "    \n",
    "    vol_sample = vol[pos[:cnt_sample]]\n",
    "    ob_sample = ob[pos[:cnt_sample]]\n",
    "    \n",
    "    # feature first\n",
    "    ob_sample = np.transpose(ob_sample, [2, 0, 1])\n",
    "    \n",
    "    \n",
    "    # --- PLOT\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(5, 3, figsize=(15,15))\n",
    "    fig.suptitle(\"Time interval \" + str(i-1), fontsize = 15)\n",
    "    \n",
    "    # hist\n",
    "    ax[0][0].hist(df_gate['ob'], histtype='bar', bins = bin_bound,  \\\n",
    "               label='Gate distribution of order book \\n in the testing data ')\n",
    "    ax[0][0].set_ylim(0,300)\n",
    "    ax[0][0].legend(fontsize=10)\n",
    "    \n",
    "    # truth and prediction\n",
    "#     ax[0][1].plot(df_pre['truth'], label = 'Truth')\n",
    "    ax[0][1].plot(df_pre['pre'],   label = 'Prediction', linewidth = 4)\n",
    "    ax[0][1].plot(df_pre['pre_v'], label = 'pre_v')\n",
    "    ax[0][1].plot(df_pre['pre_b'],   label = 'pre_b')\n",
    "    ax[0][1].set_ylim([0.0, 3.0])\n",
    "    ax[0][1].legend()\n",
    "    \n",
    "    \n",
    "    # gate distribution\n",
    "    X = range(len(tmp_gate))\n",
    "    Y =  [1.0 for k in tmp_gate ]\n",
    "    Y1 = [k[0] for k in tmp_gate]\n",
    "    Y2 = [0.0 for k in tmp_gate]\n",
    "    \n",
    "    ax[0][2].plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "    ax[0][2].plot(Y1,label = 'Volatility', color = 'k', alpha=.1)\n",
    "    ax[0][2].plot(Y2,)\n",
    "    ax[0][2].fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "    ax[0][2].fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "    \n",
    "    \n",
    "    # features\n",
    "    ob = np.transpose(ob, [2, 1, 0])\n",
    "    print  np.shape(ob)\n",
    "    \n",
    "    max_ob = np.max(ob[0], 0)\n",
    "    min_ob = np.min(ob[0], 0)\n",
    "    ax[1][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][0].set_ylim([0,10])\n",
    "    ax[1][0].set_title(features_ob[0])\n",
    "    \n",
    "    max_ob = np.max(ob[1], 0)\n",
    "    min_ob = np.min(ob[1], 0)\n",
    "    ax[1][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][1].set_ylim([0,10])\n",
    "    ax[1][1].set_title(features_ob[1])\n",
    "    \n",
    "    max_ob = np.max(ob[2], 0)\n",
    "    min_ob = np.min(ob[2], 0)\n",
    "    ax[1][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[1][2].set_ylim([0,350])\n",
    "    ax[1][2].set_title(features_ob[2])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[3], 0)\n",
    "    min_ob = np.min(ob[3], 0)\n",
    "    ax[2][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][0].set_ylim([0,500])\n",
    "    ax[2][0].set_title(features_ob[3])\n",
    "    \n",
    "    max_ob = np.max(ob[4], 0)\n",
    "    min_ob = np.min(ob[4], 0)\n",
    "    ax[2][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][1].set_ylim([0,200])\n",
    "    ax[2][1].set_title(features_ob[4])\n",
    "    \n",
    "    max_ob = np.max(ob[5], 0)\n",
    "    min_ob = np.min(ob[5], 0)\n",
    "    ax[2][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[2][2].set_ylim([0,5000])\n",
    "    ax[2][2].set_title(features_ob[5])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[6], 0)\n",
    "    min_ob = np.min(ob[6], 0)\n",
    "    ax[3][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][0].set_ylim([0,5000])\n",
    "    ax[3][0].set_title(features_ob[6])\n",
    "    \n",
    "    max_ob = np.max(ob[7], 0)\n",
    "    min_ob = np.min(ob[7], 0)\n",
    "    ax[3][1].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][1].set_ylim([-4000,4000])\n",
    "    ax[3][1].set_title(features_ob[7])\n",
    "    \n",
    "    max_ob = np.max(ob[8], 0)\n",
    "    min_ob = np.min(ob[8], 0)\n",
    "    ax[3][2].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[3][2].set_ylim([0,2000])\n",
    "    ax[3][2].set_title(features_ob[8])\n",
    "    \n",
    "    \n",
    "    max_ob = np.max(ob[9], 0)\n",
    "    min_ob = np.min(ob[9], 0)\n",
    "    ax[4][0].fill_between(X, max_ob, min_ob, color='k',alpha=.5)\n",
    "    ax[4][0].set_ylim([0,4000])\n",
    "    ax[4][0].set_title(features_ob[9])\n",
    "    \n",
    "    \n",
    "    # price at minutes\n",
    "    ax[4][1].plot(price_minu_ts)\n",
    "#     ax[4][1].set_title('Temporal dependency on order book')\n",
    "#     ax[4][1].set(xlabel='Temporal lags')\n",
    "    ax[4][1].set_ylim([200, 800])\n",
    "    \n",
    "    # feature weights\n",
    "    handler = ax[4][2].bar( range(len(np.squeeze(abs_gate_para[3])) ), np.squeeze(abs_gate_para[3]))\n",
    "    ax[4][2].set_title('Feature weight of order book')\n",
    "    tmp_ind = range(len(np.squeeze(abs_gate_para[3])))\n",
    "    ax[4][2].set_ylim([0, 1.0])\n",
    "    plt.xticks( tmp_ind , features_ob, rotation=50 )\n",
    "    \n",
    "    \n",
    "    # save figure\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    fig.savefig('../bt_results/res/pics/test_' + str(i-1) + '.jpeg', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# residual investigation\n",
    "\n",
    "def residual_cmparison_sig_test(models, file_path, prefix, file_col_names):\n",
    "    \n",
    "    postfix = '.txt'\n",
    "\n",
    "    mix_ts = prefix + 'mix' + postfix\n",
    "    mix_df = pd.read_csv( file_path + mix_ts, sep=',', names = file_col_names )\n",
    "    mix_res = mix_df['truth'] - mix_df['pre']\n",
    "    \n",
    "    for i in models:\n",
    "        \n",
    "        tmp_path = prefix_ts + i + postfix\n",
    "        tmp_df = pd.read_csv(file_path + tmp_path, sep=',', names = ['truth', 'pre'])\n",
    "    \n",
    "        tmp_res = tmp_df['truth'] - tmp_df['pre']\n",
    "    \n",
    "        print  i, ':', stats.ks_2samp( np.asarray(mix_res), np.asarray(tmp_res) )\n",
    "        \n",
    "def residual_test(models, file_path, prefix, file_col_names):\n",
    "    \n",
    "    postfix = '.txt'\n",
    "\n",
    "    mix_ts = prefix + 'mix' + postfix\n",
    "    mix_df = pd.read_csv( file_path + mix_ts, sep=',', names = file_col_names)\n",
    "    mix_res = mix_df['truth'] - mix_df['pre']\n",
    "    \n",
    "    print 'mix', stats.kstest(np.asarray(mix_res), 'norm')\n",
    "    \n",
    "    print sm.stats.diagnostic.acorr_ljungbox(np.asarray(mix_res), lags = 5, boxpierce=False)[1]\n",
    "    \n",
    "#     print acf(  mix_res)  \n",
    "#     print pacf( mix_res )\n",
    "    \n",
    "    for i in models:\n",
    "        \n",
    "        tmp_path = prefix_ts + i + postfix\n",
    "        tmp_df = pd.read_csv(file_path + tmp_path, sep=',', names = ['truth', 'pre'])\n",
    "    \n",
    "        tmp_res = tmp_df['truth'] - tmp_df['pre']\n",
    "    \n",
    "        print i,':', stats.kstest(np.asarray(tmp_res), 'norm')\n",
    "        \n",
    "        print 'test for no autocorrelation: ', \\\n",
    "        sm.stats.diagnostic.acorr_ljungbox(np.asarray(tmp_res), lags = 5, boxpierce=False)[1]\n",
    "        \n",
    "        \n",
    "def residual_plot(models, file_path, prefix, file_col_names):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches( 17,8 )\n",
    "    \n",
    "    postfix = '.txt'\n",
    "\n",
    "    mix_ts = prefix + 'mix' + postfix\n",
    "    mix_df = pd.read_csv( file_path + mix_ts, sep=',', names = file_col_names)\n",
    "    mix_res = mix_df['truth'] - mix_df['pre']\n",
    "    \n",
    "    ax.plot(mix_res, lw=1, label = 'mixture')\n",
    "    \n",
    "#     for i in models:\n",
    "        \n",
    "#         tmp_path = prefix_ts + i + postfix\n",
    "#         tmp_df = pd.read_csv(file_path + tmp_path, sep=',', names = ['truth', 'pre'])\n",
    "    \n",
    "#         tmp_res = tmp_df['truth'] - tmp_df['pre']\n",
    "    \n",
    "#         print i,':', stats.kstest(np.asarray(tmp_res), 'norm')\n",
    "        \n",
    "#         ax.plot( tmp_res, lw = 1, label = i )\n",
    "    \n",
    "    ax.legend( loc=0)\n",
    "    ax.set_ylim(-1.5, 1.5)\n",
    "    \n",
    "def mixture_weight_condition_on_vol( gate, y, lower, upper ):\n",
    "   \n",
    "    tmpv = []\n",
    "    tmpob= []\n",
    "    gate = np.asarray(gate)\n",
    "    for i in range(1,len(gate)):\n",
    "        tmp_v =  gate[i][0]\n",
    "        tmp_ob = gate[i][1]\n",
    "        \n",
    "        if y[i] >=lower and y[i]<=upper:\n",
    "            tmpv.append(tmp_v)\n",
    "            tmpob.append(tmp_ob)\n",
    "    \n",
    "    print lower, upper, \" : \", len(tmpv), mean(tmpv), mean(tmpob),' p-value: ', sp.stats.ttest_ind(tmpv,tmpob)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ---- conditional error evaluation ----\n",
    "\n",
    "# gate interval: error of mixture, errors of baseline models\n",
    "\n",
    "models = ['gbt', 'rf', 'xgt', 'bayes', 'lasso', 'gp', 'enet', 'ridge']\n",
    "#, 'arima'\n",
    "#'arimax'\n",
    "#'str', 'strx', \n",
    "# , 'garch', 'egarch'\n",
    "\n",
    "def err_conditional_on_gate( gate_range, gate, models, path, prefix ):\n",
    "    \n",
    "    pos = []\n",
    "    for i in range(len(gate)):\n",
    "        if gate[i][1]>gate_range[0] and gate[i][1]<gate_range[1]:\n",
    "            pos.append(i)\n",
    "    num = len(pos)\n",
    "    print num\n",
    "    \n",
    "    postfix = '.txt'\n",
    "    mix_name = prefix + 'mix' + postfix\n",
    "    mix_df = pd.read_csv( path + mix_name, sep=',', names = ['truth', 'pre', 'pre_v', 'pre_b'] )\n",
    "    \n",
    "    mix_arr = np.asarray(mix_df[['truth','pre']])\n",
    "    mix_pos = mix_arr[pos]\n",
    "    print len(mix_pos)\n",
    "    \n",
    "    tr = np.transpose(mix_pos,[1,0])[0]\n",
    "    pre = np.transpose(mix_pos,[1,0])[1]\n",
    "    \n",
    "    print 'mix', sqrt(mean((tr-pre)*(tr-pre)))\n",
    "\n",
    "    for i in models:\n",
    "        \n",
    "        print i\n",
    "        \n",
    "        file_name = prefix + i + postfix\n",
    "        tmp_df = pd.read_csv(path + file_name, sep=',', names = ['truth', 'pre'])\n",
    "        \n",
    "        tmp_arr = np.asarray(tmp_df[['truth','pre']])\n",
    "        tmp_pos = tmp_arr[pos]\n",
    "#         print len(mix_pos)\n",
    "    \n",
    "        tr = np.transpose(tmp_pos,[1,0])[0]\n",
    "        pre = np.transpose(tmp_pos,[1,0])[1]\n",
    "        print  sqrt(mean((tr-pre)*(tr-pre)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize patterns of mixtures\n",
    "\n",
    "def pattern_conditional_on_gate( gate_range, gate, dta_v, dta_distr, ylimits, ydata ):\n",
    "    pos = []\n",
    "    for i in range(len(gate)):\n",
    "        if gate[i][1]>gate_range[0] and gate[i][1]<gate_range[1]:\n",
    "            pos.append(i)\n",
    "    num = len(pos)\n",
    "    print num\n",
    "    \n",
    "    \n",
    "    np.random.shuffle(pos)\n",
    "    if num<100:\n",
    "        cnt_sample = num\n",
    "    else:\n",
    "        cnt_sample = 100\n",
    "        \n",
    "    \n",
    "    tmplen   = 10\n",
    "    subseq_y = []\n",
    "    for i in range(cnt_sample):\n",
    "        if pos[i] + tmplen < len(ydata):\n",
    "            subseq_y.append( ydata[pos[i]:pos[i]+tmplen] )\n",
    "    \n",
    "    subseq_y = np.asarray(subseq_y)\n",
    "    vsample = dta_v[pos[:cnt_sample]]\n",
    "    dsample = dta_distr[pos[:cnt_sample]]\n",
    "    print np.shape(vsample), np.shape(dsample)\n",
    "\n",
    "\n",
    "    # plot auto-regressive and subsequent volatility\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(17,5))\n",
    "    # fig.set_size_inches( 18,7 )\n",
    "    ax1.boxplot(vsample);\n",
    "    ax1.set_ylim(0,5.0)\n",
    "    \n",
    "    ax2.boxplot(subseq_y);\n",
    "    ax2.set_ylim(0,5.0)\n",
    "    \n",
    "    \n",
    "    # plot order book feature patterns\n",
    "    trans_dsample = np.transpose(dsample, [2, 0, 1])\n",
    "\n",
    "    fig, ax_list = plt.subplots(2, 5, figsize=(19,10))\n",
    "    for i in range(2):\n",
    "        for j in range(5):\n",
    "            \n",
    "            feature_idx = i*5+j\n",
    "            step_data = []\n",
    "\n",
    "            ax_list[i][j].boxplot( trans_dsample[feature_idx] )\n",
    "            ax_list[i][j].set_ylim( ylimits[feature_idx][0], ylimits[feature_idx][1] )\n",
    "\n",
    "# ----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pattern_conditional_on_gate( [0.0, 0.2], gate_tr, dta_v, dta_distr, ylimits, ytrain )\n",
    "\n",
    "pattern_conditional_on_gate( [0.2, 0.4], gate_tr, dta_v, dta_distr, ylimits, ytrain )\n",
    "\n",
    "pattern_conditional_on_gate( [0.4, 0.6], gate_tr, dta_v, dta_distr, ylimits, ytrain )\n",
    "\n",
    "pattern_conditional_on_gate( [0.6, 1.0], gate_tr, dta_v, dta_distr, ylimits, ytrain )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def errorfill(x, y, yerr, interval, color=None, alpha_fill=0.3, ax=None):\n",
    "    ax = ax if ax is not None else plt.gca()\n",
    "    if color is None:\n",
    "        color = ax._get_lines.color_cycle.next()\n",
    "    if np.isscalar(yerr) or len(yerr) == len(y):\n",
    "        ymin = y - yerr\n",
    "        ymax = y + yerr\n",
    "    elif len(yerr) == 2:\n",
    "        ymin, ymax = yerr\n",
    "    ax.plot(x, y, color=color)\n",
    "    ax.set_ylim(interval)\n",
    "    ax.fill_between(x, ymax, ymin, color=color, alpha=alpha_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mixture_gate_condition_on_vol( pre, gate, y, lower, upper ):\n",
    "   \n",
    "    tmpv = []\n",
    "    tmpob= []\n",
    "\n",
    "    gatev = []\n",
    "    gateob= []\n",
    "    \n",
    "    gate = np.asarray(gate)\n",
    "    pre = np.asarray(pre)\n",
    "    \n",
    "    gateup = 0\n",
    "    \n",
    "    for i in range(1,len(gate)):\n",
    "        tmp_v =  pre[i][2]\n",
    "        tmp_ob = pre[i][3]\n",
    "        \n",
    "        g_v =  gate[i][0]\n",
    "        g_ob = gate[i][1]\n",
    "        \n",
    "        if pre[i][0] >=lower and pre[i][0]<=upper and  pre[i][0] < pre[i-1][0] :\n",
    "            tmpv.append(tmp_v)\n",
    "            tmpob.append(tmp_ob)\n",
    "            \n",
    "            gatev.append(g_v)\n",
    "            gateob.append(g_ob)\n",
    "            \n",
    "            if g_ob < gate[i-1][1]:\n",
    "                gateup+=1\n",
    "            \n",
    "    \n",
    "    print lower, upper, \" : \", len(tmpv), mean(tmpv), mean(gatev), \\\n",
    "    mean(tmpob), mean(gateob), gateup/(len(gateob)+1e-10), gateup, len(gateob) \n",
    "#     ' p-value: ', sp.stats.ttest_ind(tmpv,tmpob)[1]\n",
    "\n",
    "mix_pre_train = pd.read_csv(file_path + 'pytrain_mix.txt', sep=',', names = name_format)\n",
    "mix_pre_test  = pd.read_csv(file_path + 'pytest_mix.txt',  sep=',', names = name_format)\n",
    "\n",
    "\n",
    "print 'Training:'\n",
    "for i in range(0,60):\n",
    "    mixture_gate_condition_on_vol( mix_pre_train, gate_tr, ytrain, 0.01*i, 0.01*(i+1) )\n",
    "    \n",
    "    \n",
    "print '\\nTesting:'\n",
    "for i in range(1,50):\n",
    "    mixture_gate_condition_on_vol( mix_pre_test, gate_ts, ytest, 0.01*i, 0.01*(i+1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "# backup\n",
    "\n",
    "#---- log sq ----\n",
    "\n",
    "test_df = pd.read_csv('res/pytest.txt',    sep=',', names = ['pred', 'true'])\n",
    "gate_tr = pd.read_csv('res/gate_train.txt',sep=',', names = ['vol','ob'])\n",
    "gate_ts = pd.read_csv('res/gate_test.txt', sep=',', names = ['vol','ob'])\n",
    "print test_df.shape, gate_tr.shape, gate_ts.shape\n",
    "\n",
    "plot_horizon = 20\n",
    "plot_prediction_truth('res/pytest.txt', 'Mixture linear', plot_horizon)\n",
    "tmp_gate =  np.asarray(gate_ts.iloc[:plot_horizon])\n",
    "\n",
    "# for i in range(3, len(tmp_gate)-3):\n",
    "#      tmp_gate[i][0] = mean([tmp_gate[j][0] for j in range(i-1, i+1)])\n",
    "\n",
    "X = range(len(tmp_gate))\n",
    "Y =  [1.0 for i in tmp_gate ]\n",
    "Y1 = [i[0] for i in tmp_gate]\n",
    "Y2 = [0.0 for i in tmp_gate]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches( 18,7 )\n",
    "\n",
    "ax.plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "ax.plot(Y1,label = 'Volatility', color = 'y')\n",
    "ax.plot(Y2,)\n",
    "plt.fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "plt.fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "\n",
    "#---- sq ----\n",
    "\n",
    "test_df = pd.read_csv('../bt_results/res/pytest.txt',    sep=',', names = ['pred', 'true'])\n",
    "gate_tr = pd.read_csv('../bt_results/res/gate_train.txt',sep=',', names = ['vol','ob'])\n",
    "gate_ts = pd.read_csv('../bt_results/res/gate_test.txt', sep=',', names = ['vol','ob'])\n",
    "print test_df.shape, gate_tr.shape, gate_ts.shape\n",
    "\n",
    "plot_l = 0\n",
    "plot_r = 250\n",
    "\n",
    "plot_prediction_truth('../bt_results/res/pytest.txt', 'Mixture linear', plot_l, plot_r)\n",
    "tmp_gate =  np.asarray(gate_ts.iloc[plot_l:plot_r])\n",
    "\n",
    "#for i in range(3, len(tmp_gate)-3):\n",
    " #    tmp_gate[i][0] = mean([tmp_gate[j][0] for j in range(i-1, i+1)])\n",
    "\n",
    "X = range(len(tmp_gate))\n",
    "Y =  [1.0 for i in tmp_gate ]\n",
    "Y1 = [i[0] for i in tmp_gate]\n",
    "Y2 = [0.0 for i in tmp_gate]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches( 18,7 )\n",
    "\n",
    "ax.plot(Y, label = 'Order book', color='k', alpha=.5)\n",
    "ax.plot(Y1,label = 'Volatility', color = 'y')\n",
    "ax.plot(Y2,)\n",
    "plt.fill_between(X, Y, Y1, color='k',alpha=.5)\n",
    "plt.fill_between(X, Y1,Y2, color='y',alpha=.5)\n",
    "\n",
    "ax.legend(loc=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
